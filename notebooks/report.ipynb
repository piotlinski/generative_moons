{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training generative model on moons dataset\n",
    "\n",
    "> The objective of this notebook is to train a generative model on the [moons dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_moons.html). The model used is a Variational Autoencoder (VAE) with a simple architecture, trained without and with conditioning on moon identity. The code is written in PyTorch, extended with Lightning and Hydra for training and configuration management.\n",
    "\n",
    "> This repository was based on [Lightning Hydra Template](https://github.com/ashleve/lightning-hydra-template).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This notebook presents an exploration of training generative models on the moons dataset, with a particular focus on leveraging the Variational Autoencoder (VAE) framework. The moons dataset, despite its simplicity, offers a two-dimensional, non-linear pattern that poses a challenge for generative models. Variational Autoencoders are a class of generative models that learn a probabilistic mapping from a latent space to the data space, allowing for both efficient data compression and generation. VAEs differ from traditional autoencoders by introducing a probabilistic interpretation of the latent variables, which enables them to generate new, unseen samples by sampling from the learned latent distribution.\n",
    "\n",
    "The aim of this report is to train a VAE on the moons dataset and analyze its generative performance, by reviewing the quality of the generated samples and the learned latent space. Additionally, it explores the impact of conditioning the VAE on the moon identity on the generative performance.\n"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variational Autoencoders (VAEs)\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "Variational Autoencoders (VAEs) are a class of generative models belonging to the family of **Latent Variable Models**. These models are based on an assumption that the data $\\mathcal{X}$ is *generated* from a continuous latent variable $\\mathcal{Z}$, which is not directly observed, via a probabilistic process. This involves specifying a joint distribution over the observed and latent variables $P(\\mathbf{x},\\mathbf{z})$\n",
    "\n",
    "$$P(\\mathbf{x},\\mathbf{z})=P(\\mathbf{x} | \\mathbf{z})P(\\mathbf{z})$$\n",
    "\n",
    "where $P(\\mathbf{z})$ is the prior distribution over the latent variables and $P(\\mathbf{x} | \\mathbf{z})$ is the likelihood of the data given the latent variables. Here, we assume that both distributions are parameterized by $\\theta$ and their probability density functions are continuous. In VAEs, the dependency of the data $\\mathbf{x}$ on the latent variables $\\mathbf{z}$ is modeled by a neural network with parameters $\\theta$, which is referred to as **the decoder** $P_\\theta(\\mathbf{x} | \\mathbf{z})$.\n",
    "\n",
    "In this setup, $P(\\mathbf{x})$ can be obtained by marginalizing out the latent variables:\n",
    "\n",
    "$$P(\\mathbf{x})=\\int P_\\theta(\\mathbf{x} | \\mathbf{z})P(\\mathbf{z})d\\mathbf{z}$$\n",
    "\n",
    "The objective of training latent variable model is to find the parameters $\\theta$ that **maximize the likelihood of the observed data**. However, computing the likelihood $P(\\mathbf{x})$ is intractable in most cases, as it involves marginalizing over the latent variables. To address this issue, VAEs introduce an **approximate inference model** $Q_\\phi(\\mathbf{z} | \\mathbf{x})$ that approximates the true posterior $P(\\mathbf{z} | \\mathbf{x})$. This model, often referred to as **the encoder**, is parameterized by $\\phi$ and is used to infer the latent variables given the observed data.\n",
    "\n",
    "In this setup, the objective can be formulated as below:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "    \\log p_\\theta\\left(\\mathbf{x}\\right) & = \\mathbb{E}_{\\mathbf{z} \\sim q_\\phi\\left(\\mathbf{z} | \\mathbf{x}\\right)} \\left[\\log p_\\theta\\left(\\mathbf{x}\\right)\\right] & \\text{$p_\\theta\\left(\\mathbf{x}\\right)$ is independent of $\\mathbf{z}$}\\\\\n",
    "    & = \\mathbb{E}_{\\mathbf{z}}\\left[\\log\\frac{p_\\theta\\left(\\mathbf{x} | \\mathbf{z}\\right)p\\left(\\mathbf{z}\\right)}{p\\left(\\mathbf{z} | \\mathbf{x}\\right)}\\right] & \\text{Bayes Theorem}\\\\\n",
    "    & = \\mathbb{E}_{\\mathbf{z}}\\left[\\log\\frac{p_\\theta\\left(\\mathbf{x} | \\mathbf{z}\\right)p\\left(\\mathbf{z}\\right)}{p\\left(\\mathbf{z} | \\mathbf{x}\\right)}\\frac{q_\\phi\\left(\\mathbf{z} | \\mathbf{x}\\right)}{q_\\phi\\left(\\mathbf{z} | \\mathbf{x}\\right)}\\right] & \\text{multiply by 1}\\\\\n",
    "    & = \\mathbb{E}_{\\mathbf{z}}\\left[\\log p_\\theta\\left(\\mathbf{x} | \\mathbf{z}\\right)\\right] - \\mathbb{E}_{\\mathbf{z}}\\left[\\log \\frac{q_\\phi\\left(\\mathbf{z} | \\mathbf{x}\\right)}{p\\left(\\mathbf{z}\\right)}\\right] + \\mathbb{E}_{\\mathbf{z}}\\left[\\log \\frac{q_\\phi\\left(\\mathbf{z} | \\mathbf{x}\\right)}{p\\left(\\mathbf{z} | \\mathbf{x}\\right)}\\right] & \\text{logarithm}\\\\\n",
    "    & = \\underbrace{\\mathbb{E}_{\\mathbf{z}}\\left[\\log p_\\theta\\left(\\mathbf{x} | \\mathbf{z}\\right)\\right] - D_{KL}\\left(q_\\phi\\left(\\mathbf{z} | \\mathbf{x}\\right)\\| p\\left(\\mathbf{z}\\right)\\right)}_{\\mathcal{L}\\left(\\mathbf{x}, \\theta, \\phi\\right)} + \\underbrace{D_{KL}\\left(q_\\phi\\left(\\mathbf{z} | \\mathbf{x}\\right)\\| p\\left(\\mathbf{z} | \\mathbf{x}\\right)\\right)}_{\\ge 0}\\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Calculating the KL divergence between the true posterior and its approximation is intractable, but it is always non-negative. Therefore, the objective function $\\mathcal{L}\\left(\\mathbf{x}, \\theta, \\phi\\right)$ is a lower bound on the log-likelihood of the data. This lower bound is known as the **Evidence Lower Bound (ELBO)** and is maximized during training. Intuitively, the ELBO consists of two terms: **the reconstruction loss**, which measures the difference between the input data and the reconstructed data, and **the KL divergence** between the approximate posterior and the prior. Usually, the prior is chosen to be a standard normal distribution $\\mathcal{N}(0, \\mathbf{I})$.\n",
    "\n",
    "### Reparametrization trick\n",
    "\n",
    "One of the challenges in training VAEs is that backpropagation can't flow through the sampling operation in the encoder. To address this issue, the **reparametrization trick** is used, which involves sampling from a simple distribution (e.g., standard normal) ($\\epsilon \\sim \\mathcal{N}(0,\\mathbf{I})$) and transforming the samples to the desired distribution using the parameters predicted by the encoder.\n",
    "\n",
    "$$\\mathbf{z} = \\mathbf{\\mu}(\\mathbf{x}) + \\mathbf{\\sigma}(\\mathbf{x}) \\odot \\epsilon$$\n",
    "\n",
    "The reparametrization allows gradients to flow through the encoder, enabling end-to-end training of the VAE.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditional Variational Autoencoders (CVAEs)\n",
    "\n",
    "Conditional Variational Autoencoders (CVAEs) are an extension to the standard VAE framework that allows for conditioning the generative model on additional information. In CVAEs, both the encoder and the decoder are conditioned on the auxiliary information, such as class labels, denoted as $\\mathbf{y}$. The inclusion of conditioning allows more control over the generative process.\n",
    "\n",
    "In a CVAE, the joint distribution of the observed data is expressed as:\n",
    "\n",
    "$$P(\\mathbf{x}, \\mathbf{z} | \\mathbf{y}) = P(\\mathbf{x} | \\mathbf{z}, \\mathbf{y})P(\\mathbf{z} | \\mathbf{y})$$\n",
    "\n",
    "Here, the prior distribution $P(\\mathbf{z} | \\mathbf{y})$ and the likelihood $P(\\mathbf{x} | \\mathbf{z}, \\mathbf{y})$ are conditioned on the auxiliary information $\\mathbf{y}$. The formulation of the ELBO in CVAEs is similar to the standard VAE, but the encoder and decoder are conditioned on the auxiliary information. In practice, the conditioning can be achieved by concatenating the auxiliary information to the input data and the latent variables.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset and preprocessing\n",
    "\n",
    "The moons dataset is a synthetic dataset generated using the `make_moons` function from `scikit-learn`. It consists of two interleaving half circles, making it a non-linear dataset. Its key parameters are:\n",
    "- `n_samples`: the total number of samples to generate\n",
    "- `noise`: the standard deviation of Gaussian noise added to the data\n",
    "- `random_state`: the random seed used for generating the data\n",
    "\n",
    "During initial exploration, applying normalization didn't affect the performance of the model due to the original scale of the data. Therefore, no preprocessing is applied to the moons dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "from sklearn.datasets import make_moons\n",
    "\n",
    "from src.utils.visualize import visualize_data\n",
    "\n",
    "sizes = [100, 1000, 10000]\n",
    "noises = [0, 0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=len(sizes),\n",
    "    cols=len(noises),\n",
    "    subplot_titles=[f\"Size: {size}, Noise: {noise}\" for size in sizes for noise in noises],\n",
    ")\n",
    "\n",
    "\n",
    "for n_idx, noise in enumerate(noises, start=1):\n",
    "    for s_idx, size in enumerate(sizes, start=1):\n",
    "        X, y = make_moons(n_samples=size, noise=noise)\n",
    "\n",
    "        scatter = visualize_data(X, y, title=f\"Size: {size}, Noise: {noise}\")\n",
    "        for trace in range(len(scatter[\"data\"])):\n",
    "            fig.append_trace(scatter[\"data\"][trace], row=s_idx, col=n_idx)\n",
    "\n",
    "fig.update_layout(\n",
    "    height=250 * len(sizes),\n",
    "    width=250 * len(noises),\n",
    "    title=\"Moons dataset params\",\n",
    "    showlegend=False,\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation details\n",
    "\n",
    "The Moons dataset is created within a Lightning `DataModule` class, which is responsible for loading and preprocessing the data. The `MoonsDataModule` class is defined as below. The dataset is split into training, validation and test dataset, with a 60:20:20 ratio. Therefore, the initial dataset size is set to 2000 samples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Code\n",
    "\n",
    "Code(filename=\"../src/data/moons_datamodule.py\", language=\"python\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model architecture\n",
    "\n",
    "### VAE\n",
    "\n",
    "The VAE model is implemented using PyTorch and Lightning. The model architecture consists of an encoder and a decoder, both implemented as simple 1-hidden layer feedforward neural networks. The encoder maps the input data to the latent space, while the decoder reconstructs the input data from the latent space. The latent space is parameterized by the mean and log-variance of the Gaussian distribution.\n",
    "\n",
    "$$\\mu, \\rho = \\text{encoder}(\\mathbf{x}); \\mathbf{z} \\sim \\mathcal{N}(\\mu, e^{\\rho}); \\mathbf{x}_{\\text{recon}} = \\text{decoder}(\\mathbf{z})$$\n",
    "\n",
    "The neural networks use ReLU activation functions except for the output layers of both the encoder and decoder, which use linear activation functions to ensure the output is unconstrained. The implementation leverages the reparametrization trick to enable end-to-end training of the VAE, with a tuned epsilon value to control the sampling noise.\n",
    "\n",
    "The model is trained using the ELBO loss, which consists of the reconstruction loss and the KL divergence between the approximate posterior and the prior.\n",
    "\n",
    "> The ELBO loss implementation used in this project features an additional scaling factor ($\\beta$), which could be used to control the importance of the KL divergence term in the loss. The $\\beta$ parameter affects the trade-off between the reconstruction loss and the KL divergence, which can enforce a more disentangled latent space.\n",
    "\n",
    "The model is implemented as a standard torch module, with the encoder and decoder defined as separate modules.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Code(filename=\"../src/models/components/vae.py\", language=\"python\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CVAE\n",
    "\n",
    "The Conditional Variational Autoencoder (CVAE) extends the VAE model to include conditioning on the moon identity. The moon identity is a binary variable that indicates the origin of the data point (moon 0 or moon 1). The CVAE model architecture is similar to the VAE, but the encoder and decoder are conditioned on the moon identity. The moon identity is concatenated to the input data and the latent variables.\n",
    "\n",
    "$$\\mu, \\rho = \\text{encoder}(\\mathbf{x}, \\mathbf{y}); \\mathbf{z} \\sim \\mathcal{N}(\\mu, e^{\\rho}); \\mathbf{x}_{\\text{recon}} = \\text{decoder}(\\mathbf{z}, \\mathbf{y})$$\n",
    "\n",
    "The loss function used for the CVAE is formulated similarly to the VAE.\n",
    "\n",
    "The CVAE model is implemented as a torch module, inheriting from the VAE model and re-using the encoder and decoder modules. The model is defined as below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Code(filename=\"../src/models/components/cvae.py\", language=\"python\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "The training of the VAE and CVAE models is done in an unsupervised setup, where the models are trained to reconstruct the input data and learn a meaningful latent representation. Both the encoder and the decoder are trained jointly, using the ELBO loss as the objective function. Therefore, the training process could be easily implemented in plain PyTorch as below:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm.auto import trange\n",
    "\n",
    "from src.data.moons_datamodule import MoonsDataModule\n",
    "from src.models.components.vae import VAE, Decoder, Encoder, VAELoss\n",
    "\n",
    "MAX_EPOCHS = 100\n",
    "\n",
    "datamodule = MoonsDataModule(data_dir=\"../\", batch_size=64)\n",
    "datamodule.prepare_data()\n",
    "datamodule.setup()\n",
    "\n",
    "encoder = Encoder(input_dim=2, hidden_dims=32, latent_dim=32)\n",
    "decoder = Decoder(input_dim=32, hidden_dims=32, output_dim=2)\n",
    "model = VAE(encoder, decoder, eps_w=0.1)\n",
    "\n",
    "loss_fn = VAELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "for epoch in trange(MAX_EPOCHS):\n",
    "    model.train()\n",
    "\n",
    "    for x, y in datamodule.train_dataloader():\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        x_hat = model(x, y=None)\n",
    "        loss, _ = loss_fn(x_hat, x)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0\n",
    "        for x, y in datamodule.val_dataloader():\n",
    "            x_hat = model(x, y=None)\n",
    "            loss, _ = loss_fn(x_hat, x)\n",
    "            val_loss += loss\n",
    "        val_loss /= len(datamodule.val_dataloader())\n",
    "        print(f\"Epoch: {epoch}, Val loss: {val_loss.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, to allow for easier experimentation, training process logging and evaluation, the training is done using the PyTorch Lightning framework. `GenerativeLitModule` is a Lightning module that encapsulates the training and evaluation logic for both the VAE and CVAE models. The module is responsible for setting up, training and evalutaion of the model. It also handles learning rate scheduling (reducing the learning rate on a plateau).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Code(filename=\"../src/models/generative_module.py\", language=\"python\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation details\n",
    "\n",
    "The training process is managed using Hydra, allowing for organized configuration management and easy experimentation with different hyperparameters. The configuration file `train.yaml` contains the master configuration for the training process, including the data parameters, model hyperparameters, training settings, and logging options.\n",
    "\n",
    "The model training was conducted on a CPU, using the Adam optimizer. Each model was trained for maximum 1000 epochs, with early stopping based on the validation loss. The training process was monitored in Weights & Biases [generative_moons](https://wandb.ai/piotlinski/generative_moons) project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Code(filename=\"../configs/train.yaml\", language=\"yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Using Hydra enables quick hyperparameter tuning using Optuna. In this report, the following list of hyperparameters values was searched:\n",
    "- `model.optimizer.lr`: the learning rate of the optimizer\n",
    "- `data.batch_size`: the batch size used during training\n",
    "- `model.model.encoder.hidden_dims`: the size of the hidden layer in the encoder\n",
    "- `model.model.decoder.hidden_dims`: the size of the hidden layer in the decoder\n",
    "- `model.model.encoder.latent_dim`: the size of the latent space\n",
    "\n",
    "The objective of the optimization was to minimize the mean squared error on the validation dataset. The optimization uses the TPE sampler, with 100 trials.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "The evaluation of the generative models is done by analyzing the quality of the generated samples and the learned latent space. In this project, the evaluation is done by:\n",
    "- Reviewing the value of the reconstruction loss (mean squared error)\n",
    "- Analyzing the KL divergence term\n",
    "- Visualizing the generated samples and comparing them to the original data\n",
    "- Visualizing the learned latent space and the distribution of the latent variables (using UMAP)\n",
    "- Exploring the influence of modifying the latent variables on the generated samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results and discussion\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "generative_moons",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
